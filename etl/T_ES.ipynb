{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### INITIAL CONFIGURATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USED LIBRARIES\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ FILES\n",
    "trips = pd.read_csv(r'..\\data_in\\T\\ES\\trips.txt', sep=\",\") # viajes distintos que hay\n",
    "calendar = pd.read_csv(r'..\\data_in\\T\\ES\\calendar.txt', sep=\",\") # que dias ocurre el tipo de viaje\n",
    "calendar_dates = pd.read_csv(r'..\\data_in\\T\\ES\\calendar_dates.txt', sep=\",\") # excepciones a la tabla calendar\n",
    "stop_times = pd.read_csv(r'..\\data_in\\T\\ES\\stop_times.txt', sep=\",\") # paradas de cada viaje\n",
    "stations = pd.read_csv(r'..\\data_in\\T\\ES\\stops.txt', sep=\",\") # estaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TRANSFORM INITIAL TABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVING NOT USED COLUMNS\n",
    "calendar = calendar[[\"service_id\", \"start_date\", calendar.columns[9]]]\n",
    "stop_times = stop_times[[\"trip_id\", \"stop_id\", \"stop_sequence\"]]\n",
    "stations = stations[[\"stop_id\", \"stop_name\", \"stop_lat\", \"stop_lon\"]]\n",
    "calendar_dates.drop(columns = calendar_dates.columns[2], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RENAME COLUMNS\n",
    "column_names = {'stop_id':'station_id',\n",
    "    \"stop_name\":\"station_name\",\n",
    "    \"stop_lat\":\"station_latitud\",\n",
    "    \"stop_lon\":\"station_longitud\"}\n",
    "stations.rename(columns = column_names, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE COLUMNS DATA TYPE TO DATETIME\n",
    "calendar['first_date'] = pd.to_datetime(calendar['start_date'], format='%Y%m%d')\n",
    "calendar['last_date'] = pd.to_datetime(calendar[calendar.columns[2]], format='%Y%m%d')\n",
    "calendar_dates['date'] = pd.to_datetime(calendar_dates['date'], format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COLUMN WITH DAYS BETWEEN START AND END OF DATES\n",
    "calendar['days_diff'] = calendar.apply(lambda x: (x['last_date'] - x['first_date']).days, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### FIND ORIGIN AND DESTINATION STATIONS OF EACH TRIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATES AN INVERSE OF THE STOP SEQUENCE TO SEE THE FINAL STOP FOR EACH TRIP\n",
    "# works as ROW_NUMBER() OVER (PARTITION BY trip_id ORDER BY stop_sequence DESC)\n",
    "stop_times['stop_sequence_inv'] = stop_times.groupby(\"trip_id\")[\"stop_sequence\"].rank(method=\"first\", ascending=False)\n",
    "stop_times[\"stop_sequence_inv\"] = stop_times[\"stop_sequence_inv\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DF WITH ONLY THE INITIAL STOP\n",
    "first_stop = stop_times.loc[stop_times['stop_sequence'] == 1]\n",
    "\n",
    "# DF WITH ONLY THE LAST STOP\n",
    "last_stop = stop_times.loc[stop_times['stop_sequence_inv'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RENAME COLUMNS\n",
    "column_names = {\"stop_id\":\"station_start_id\"}\n",
    "first_stop.rename(columns = column_names, inplace = True)\n",
    "\n",
    "column_names = {\"stop_id\":\"station_end_id\"}\n",
    "last_stop.rename(columns = column_names, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVE COLUMNS\n",
    "first_stop = first_stop[[\"trip_id\", \"station_start_id\"]]\n",
    "last_stop = last_stop[[\"trip_id\", \"station_end_id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JOIN THE FIRST AND LAST STOP TO THE TRIPS TABLE\n",
    "trips = trips.merge(first_stop, on='trip_id', how='left')\n",
    "trips = trips.merge(last_stop, on='trip_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVE COLUMNS\n",
    "trips = trips[[\"service_id\", \"station_start_id\", \"station_end_id\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CREATE FACT TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMPTY LISTS\n",
    "service_id_list = []\n",
    "dates_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ITERATE CALENDAR TABLES TO OBTAIN THE DATA\n",
    "for index, row in calendar.iterrows():\n",
    "    for i in range(0, row['days_diff'] + 1):\n",
    "        service_id_list.append(row['service_id'])\n",
    "        dates_list.append(row['first_date'] + timedelta(days=10))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE DATAFRAME WITH THE DATA\n",
    "dict_table = {'service_id': service_id_list, 'date': dates_list}\n",
    "fact_table = pd.DataFrame(dict_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COLUMN IN CALENDAR_DATES TO DIFFERENTIATE WHEN MERGING\n",
    "calendar_dates['exception'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_table = fact_table.merge(calendar_dates, on=['service_id', 'date'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## REMOVE ROWS WITH AN EXCEPTION\n",
    "fact_table = fact_table.loc[fact_table['exception'] != 1]\n",
    "\n",
    "# REMOVE COLUMN\n",
    "fact_table.drop(columns = ['exception'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MERGE TRIPS TABLE TO ADD ORIGIN AND DESTINATION STATIONS\n",
    "fact_table = fact_table.merge(trips, on=['service_id'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SAVE FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_table.to_csv(r'..\\data_out\\trips_T_ES.csv', sep=\";\", decimal=',',  index = False)\n",
    "stations.to_csv(r'..\\data_out\\stations_T_ES.csv', sep=\";\", decimal=',', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "52634da84371cba311ea128a5ea7cdc41ff074b781779e754b270ff9f8153cee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
